What is XGBoost?
XGBoost stands for Extreme Gradient Boosting. It is a powerful and popular machine learning algorithm that is widely used for classification and regression tasks, especially on tabular data.

How does it work?
XGBoost is an implementation of gradient boosting, which is a technique that builds an ensemble of decision trees sequentially.

Each new tree tries to correct the errors made by the previous trees.

It combines many "weak" models (trees that are just a little better than random guessing) to create a strong predictive model.

XGBoost uses gradient descent optimization to minimize the loss function (error) while adding trees.


# XGBoost Classification on Breast Cancer Dataset

## Project Overview

This project demonstrates the implementation of the **XGBoost** machine learning model for classification, specifically to predict whether a breast cancer tumor is **benign** or
**malignant**. The goal is to apply XGBoost to a classic medical dataset and evaluate its performance compared to other classification algorithms such as logistic regression, SVM, 
decision trees, and random forests.

XGBoost is a powerful and widely-used gradient boosting framework known for its high performance on structured/tabular data. This project shows how to train and validate an
XGBoost model on the breast cancer dataset and uses k-Fold Cross-Validation to reliably estimate its accuracy.

---

## Dataset Description

The dataset (`data.csv`) contains patient records related to breast cancer tumors, with each row representing a single patient and several features describing the characteristics of the tumor.

### Features

The dataset includes the following tumor features (not exhaustive):

* Clump Thickness
* Uniformity of Cell Size
* Uniformity of Cell Shape
* Marginal Adhesion
* Single Epithelial Cell Size
* Bare Nuclei
* Bland Chromatin
* Normal Nucleoli
* Mitoses

These features are numerical and characterize the tumor's cellular properties.

### Target Variable

* `Class`: Indicates the tumor type:

  * `2` = Benign tumor
  * `4` = Malignant tumor

The model aims to classify tumors as benign or malignant based on the features.

---

## Project Structure

* **Data Preprocessing:** Import libraries, load the dataset, and split it into training and test sets.
* **Model Training:** Build and train the XGBoost classification model (`XGBClassifier`) on the training data.
* **Evaluation:** Evaluate the model's accuracy on the test set and use k-Fold Cross-Validation (10 folds) to assess performance consistency.
* **Comparison:** Compare XGBoost accuracy with other classical classifiers like Decision Tree, Logistic Regression, SVM, etc.

---

## Key Results

* Decision Tree Classification model accuracy: **95.9%**
* XGBoost Classification model accuracy (single test set): **97.8%**
* XGBoost average accuracy with 10-Fold Cross-Validation: **96.53%** (±2% standard deviation)

These results highlight XGBoost’s superior performance on this dataset.

---

## How to Run

1. Upload the dataset (`data.csv`) into your working environment (e.g., Google Colab, Jupyter Notebook).
2. Install required libraries (XGBoost is pre-installed in Google Colab).
3. Run the notebook to preprocess data, train the XGBoost classifier, and evaluate the results.
4. Observe the accuracy metrics and confusion matrix output.

---

## Dependencies

* Python 3.x
* pandas
* numpy
* scikit-learn
* xgboost

---

## References

* Dataset source: Breast Cancer Wisconsin Dataset (publicly available)
* XGBoost documentation: [https://xgboost.readthedocs.io/en/stable/](https://xgboost.readthedocs.io/en/stable/)

---

