
### 2.7 Random Forest Classification
- **Ensemble of decision trees**.
- **Reduces overfitting** and improves accuracy.
- **Combines** results from multiple trees using majority vote.


# ðŸŒ² Random Forest Classification - Social Network Ads

## ðŸ“Œ Project Overview

This project implements a **Random Forest Classifier** to predict whether a customer will purchase a luxury SUV based on their 
**Age** and **Estimated Salary**. The goal is to help a car dealership effectively target customers through social media
advertisements by identifying those most likely to buy the new SUV model.

This model is part of a broader machine learning classification series and represents the final and most advanced model
in the sequence, building on earlier models such as Logistic Regression, K-Nearest Neighbors, and Decision Tree Classification.

---

## ðŸ“‚ Dataset Description

- **File**: `Social_Network_Ads.csv`
- **Rows**: 400 customers (observations)
- **Features (X)**:
  - `Age`: Customer's age in years
  - `EstimatedSalary`: Annual salary in USD
- **Target (y)**:
  - `Purchased`: Binary class (1 if customer purchased the SUV, 0 if not)

Each row represents a unique customer. The goal is to train a model that can learn the patterns between Age, Salary, 
and purchase decision, and use that knowledge to predict future behavior.

---

## ðŸŒ³ What is Random Forest Classification?

A **Random Forest** is an ensemble machine learning algorithm that combines the predictions of multiple decision trees to
improve classification accuracy and control overfitting. It works by:

- Creating multiple decision trees (a "forest") during training
- Each tree is trained on a random subset of the data (bagging)
- The final prediction is made via majority voting from all trees

For this project:
- We use **10 estimators (trees)**
- Criterion: `'entropy'` to measure information gain
- `random_state=0` to ensure reproducibility

---

## ðŸ§° Tools and Libraries Used

- Python
- Pandas
- NumPy
- Matplotlib
- scikit-learn (`sklearn`)

---

## âœ… Implementation Steps

1. **Importing Libraries & Dataset**
2. **Data Preprocessing**:
   - Splitting dataset into Training and Test sets
   - Feature Scaling
3. **Building the Random Forest Classifier**:
   ```python
   from sklearn.ensemble import RandomForestClassifier
   classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)
   classifier.fit(X_train, y_train)
