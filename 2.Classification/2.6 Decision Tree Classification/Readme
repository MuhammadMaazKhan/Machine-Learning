### 2.6 Decision Tree Classification
- **Splits data**: Based on feature conditions to make decisions.
- **Easy to understand** and visualize.
- **Overfits easily** on small datasets, so use pruning or ensembles.


# ğŸŒ³ Decision Tree Classification - Social Network Ads

## ğŸ“Œ Project Overview

This project demonstrates how to implement a **Decision Tree Classifier** using Python and the `scikit-learn` library to predict
whether a customer will purchase a luxury SUV. The model is trained on a dataset containing age and estimated salary information of 
400 customers from a car dealership that launched a new SUV. The aim is to help the marketing team identify potential buyers and
target them more effectively with social media ads.

---

## ğŸ“ Dataset Description

- **Dataset**: `Social_Network_Ads.csv`
- **Rows**: 400 customers
- **Features**:
  - `Age`
  - `EstimatedSalary`
- **Target**:
  - `Purchased` (1 = bought SUV, 0 = didnâ€™t buy SUV)

---

## ğŸŒŸ What is a Decision Tree Classifier?

A **Decision Tree** is a supervised learning algorithm used for both classification and regression tasks.
It splits the data based on feature values to make predictions, using a flowchart-like structure:

- **Internal nodes** represent conditions on features
- **Branches** represent the outcome of those conditions
- **Leaves** represent final class labels or outputs

In classification, decision trees select the best features using metrics such as **Gini impurity** or **Entropy** (information gain). 
This project uses `criterion="entropy"` to align with theoretical concepts of information theory.

---

## ğŸ› ï¸ Tools and Libraries

- Python
- Pandas
- NumPy
- Matplotlib
- scikit-learn (for model training, testing, and evaluation)

---

## âœ… Steps in the Pipeline

1. **Import libraries and dataset**
2. **Data preprocessing**:
   - Splitting into training and test sets
   - Feature scaling (standardization)
3. **Model building**:
   ```python
   from sklearn.tree import DecisionTreeClassifier
   classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)
   classifier.fit(X_train, y_train)
